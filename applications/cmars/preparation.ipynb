{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input_vars**\n",
    "cbr_traffic, cbr_th, cbr_prb, cbr_queue, cbr_snr, vbr_traffic, vbr_th, vbr_prb, vbr_queue, vbr_snr, sla_level, n_utilized_prbs, prev_sla_violation\n",
    "device_count, cbr_traffic, vbr_traffic, reamaining_embb_count, reamaining_mmtc_count, remaining_prbs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Property Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_input_size = 19\n",
    "model_output_size = 15\n",
    "\n",
    "copy_one_argmax_candidate = 0\n",
    "copy_two_argmax_candidate = 13\n",
    "\n",
    "base_lower = 0.4\n",
    "base_upper = 0.8\n",
    "epsilon = 0.001\n",
    "\n",
    "DECLARATION_LINE_BASE = \"(declare-const {} Real)\"\n",
    "INPUT_CONSTRAINT_LINE_BASE = \"(assert ({} {} {}))\"\n",
    "OUTPUT_CONSTRAINT_LINE_BASE = \"(assert (<= {} {}))\"\n",
    "\n",
    "base_path = \"/home/mzi/sys-rl-verif/applications/cmars/vnnlib/plain_comparative/test/in{}_lower{}_upper{}_eps{}_out{}_{}_{}.vnnlib\"\n",
    "\n",
    "def gen_prop(copy_one_argmax_candidate=copy_one_argmax_candidate, copy_two_argmax_candidate=copy_two_argmax_candidate, \n",
    "            base_lower=base_lower, base_upper=base_upper, base_path=base_path):\n",
    "    lines = []\n",
    "    lines.append(\"; variable declaration\")\n",
    "    for i in range(2*model_input_size):\n",
    "        lines.append(DECLARATION_LINE_BASE.format(f\"X_{i}\"))\n",
    "\n",
    "    for i in range(2*model_output_size):\n",
    "        lines.append(DECLARATION_LINE_BASE.format(f\"Y_{i}\"))\n",
    "\n",
    "    lines.append(\" \")\n",
    "    lines.append(\"; input constraints\")\n",
    "    for i in range(model_input_size):\n",
    "        lines.append(INPUT_CONSTRAINT_LINE_BASE.format(\">=\", f\"X_{i}\", base_lower))\n",
    "        lines.append(INPUT_CONSTRAINT_LINE_BASE.format(\"<=\", f\"X_{i}\", base_upper))\n",
    "\n",
    "    for i in range(model_input_size):\n",
    "        lines.append(INPUT_CONSTRAINT_LINE_BASE.format(\">=\", f\"X_{model_input_size+i}\", 0.0))\n",
    "        lines.append(INPUT_CONSTRAINT_LINE_BASE.format(\"<=\", f\"X_{model_input_size+i}\", epsilon))\n",
    "\n",
    "    lines.append(\" \")\n",
    "    lines.append(\"; output constraints\")\n",
    "    for i in range(model_output_size):\n",
    "        if i == copy_one_argmax_candidate:\n",
    "            continue\n",
    "        lines.append(OUTPUT_CONSTRAINT_LINE_BASE.format(f\"Y_{i}\", f\"Y_{copy_one_argmax_candidate}\"))\n",
    "\n",
    "    for i in range(model_output_size):\n",
    "        if i == copy_two_argmax_candidate:\n",
    "            continue\n",
    "        lines.append(OUTPUT_CONSTRAINT_LINE_BASE.format(f\"Y_{model_output_size+i}\", f\"Y_{model_output_size+copy_two_argmax_candidate}\"))\n",
    "    \n",
    "    f = open(\n",
    "        base_path.format(\n",
    "        model_input_size, str(base_lower).replace(\".\", \"\"), str(base_upper).replace(\".\", \"\"), str(epsilon)[2:], \n",
    "        model_output_size, copy_one_argmax_candidate, copy_two_argmax_candidate\n",
    "        ), \n",
    "    \"w\")\n",
    "    f.write('\\n'.join(lines) )\n",
    "    f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [1, 2, 3, 4, 5, 6, 7, 8, 10 , 11, 12, 13, 14]:\n",
    "    gen_prop(copy_one_argmax_candidate=i, copy_two_argmax_candidate=i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_one_argmax_candidate, copy_two_argmax_candidate = 0, 14\n",
    "base_lower = 0.0\n",
    "base_upper = 1.0\n",
    "partition_size = 10\n",
    "\n",
    "base_path = \"/home/mzi/sys-rl-verif/applications/cmars/vnnlib/plain_comparative/10_partitions/in{}_lower{}_upper{}_eps{}_out{}_{}_{}.vnnlib\"\n",
    "\n",
    "step = float(base_upper-base_lower) / partition_size\n",
    "for i in range(partition_size):\n",
    "    gen_prop(base_path=base_path, base_lower = round(base_lower + i*step, 5), base_upper= round(base_lower + (i+1)*step, 5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CMARS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import onnx\n",
    "import sys\n",
    "sys.path.append(\"/home/mzi/sys-rl-verif/applications\")\n",
    "from cmars.lib.config_mappol import get_config\n",
    "import cmars.lib.mdp_config as mdp_config\n",
    "from cmars.lib.util import *\n",
    "from cmars.lib.rnn import *\n",
    "from cmars.lib.cnn import *\n",
    "from cmars.lib.act import *\n",
    "from cmars.lib.mlp import *\n",
    "from cmars.lib.distributions import *\n",
    "from gym import spaces\n",
    "import os\n",
    "\n",
    "parser = get_config()\n",
    "parser.add_argument(\"--add_move_state\", action='store_true', default=False)\n",
    "parser.add_argument(\"--add_local_obs\", action='store_true', default=False)\n",
    "parser.add_argument(\"--add_distance_state\", action='store_true', default=False)\n",
    "parser.add_argument(\"--add_enemy_action_state\", action='store_true', default=False)\n",
    "parser.add_argument(\"--add_agent_id\", action='store_true', default=False)\n",
    "parser.add_argument(\"--add_visible_state\", action='store_true', default=False)\n",
    "parser.add_argument(\"--add_xy_state\", action='store_true', default=False)\n",
    "parser.add_argument(\"--use_state_agent\", action='store_true', default=False)\n",
    "parser.add_argument(\"--use_mustalive\", action='store_false', default=True)\n",
    "parser.add_argument(\"--add_center_xy\", action='store_true', default=False)\n",
    "parser.add_argument(\"--use_single_network\", action='store_true', default=False)\n",
    "all_args = parser.parse_known_args()[0]\n",
    "\n",
    "class R_Actor(nn.Module):\n",
    "    def __init__(self, args, obs_space, action_space, device=torch.device(\"cpu\")):\n",
    "        super(R_Actor, self).__init__()\n",
    "        self.hidden_size = args.hidden_size\n",
    "        self._gain = args.gain\n",
    "        self._use_orthogonal = args.use_orthogonal\n",
    "        self._use_policy_active_masks = args.use_policy_active_masks\n",
    "        self._use_naive_recurrent_policy = args.use_naive_recurrent_policy\n",
    "        self._use_recurrent_policy = args.use_recurrent_policy\n",
    "        self._recurrent_N = args.recurrent_N\n",
    "        self.tpdv = dict(dtype=torch.float64, device=device)\n",
    "\n",
    "        obs_shape = get_shape_from_obs_space(obs_space)\n",
    "        base = CNNBase if len(obs_shape) == 3 else MLPBase\n",
    "        self.base = base(args, obs_shape)\n",
    "\n",
    "        if self._use_naive_recurrent_policy or self._use_recurrent_policy:\n",
    "            self.rnn = RNNLayer(self.hidden_size, self.hidden_size, self._recurrent_N, self._use_orthogonal)\n",
    "\n",
    "        self.act = ACTLayer(action_space, self.hidden_size, self._use_orthogonal, self._gain, args)\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "    def forward(self, obs, rnn_states, masks, available_actions=None, deterministic=False):\n",
    "        obs = check(obs).to(**self.tpdv)\n",
    "\n",
    "        actor_features = self.base(obs)\n",
    "        action_ligits_probs = self.act(actor_features, available_actions, deterministic)\n",
    "\n",
    "        return action_ligits_probs\n",
    "\n",
    "BASE = \"/home/mzi/sys-rl-verif/applications/cmars/models/output_{}/h{}/N{}/seed=110/lr=8e-05/critic_lr=0.001/gamma=0.4/episode_length=500/lamda_lagr=10/lagrangian_coef_rate=1e-07safety_bound=1e-05/run1/models\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_prbs=15, hidden_size=32, layer_count=1):\n",
    "    assert n_prbs in [15, 30, 80, 140]\n",
    "    assert layer_count in [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "    assert hidden_size in [32, 64, 128]\n",
    "\n",
    "    # set configs\n",
    "    all_args.layer_N = layer_count\n",
    "    all_args.hidden_size = hidden_size\n",
    "    models_path = BASE.format(n_prbs, hidden_size, layer_count)\n",
    "    embb_actor_policy = models_path + \"/actor_type_embb.pt\"\n",
    "\n",
    "    act_space = spaces.Discrete(n_prbs)\n",
    "    embb_obs_space = spaces.Box(low=0, high=10e6, shape=(mdp_config.EMBB_LOCAL_OBS_VAR_COUNT+mdp_config.AUG_LOCAL_STATE_VAR_COUNT,))\n",
    "\n",
    "    # base policy\n",
    "    device = torch.device('cpu')\n",
    "    embb_actor = R_Actor(all_args, embb_obs_space, act_space)\n",
    "    embb_actor.load_state_dict(torch.load(embb_actor_policy, map_location=device))\n",
    "\n",
    "    # remove softmax\n",
    "    class CMARS_Actor_Wrapper(nn.ModuleList):\n",
    "        def __init__(self, cmars_actor, type = \"embb\", device=torch.device(\"cpu\")):\n",
    "            super(CMARS_Actor_Wrapper, self).__init__()        \n",
    "            self.to(device)\n",
    "\n",
    "            self.af = nn.ReLU()\n",
    "            if type == \"embb\":\n",
    "                self.lin1 = nn.Linear(mdp_config.AUG_LOCAL_STATE_VAR_COUNT + mdp_config.EMBB_LOCAL_OBS_VAR_COUNT, all_args.hidden_size)\n",
    "            elif type == \"mmtc\":\n",
    "                self.lin1 = nn.Linear(mdp_config.AUG_LOCAL_STATE_VAR_COUNT + mdp_config.MMTC_LOCAL_OBS_VAR_COUNT, all_args.hidden_size)\n",
    "            else:\n",
    "                raise NotImplementedError()\n",
    "\n",
    "            self.midlayers = []\n",
    "            for i in range(all_args.layer_N):\n",
    "                self.midlayers.append(nn.Linear(all_args.hidden_size, all_args.hidden_size))\n",
    "\n",
    "            for iter, item in enumerate(self.midlayers):\n",
    "                item.weight.data = cmars_actor.base.mlp.fc2[iter][0].weight.data\n",
    "\n",
    "            for i in range(all_args.layer_N):\n",
    "                setattr(self, \"lin{}\".format(i+2), self.midlayers[i])\n",
    "\n",
    "            self.out = nn.Linear(all_args.hidden_size, n_prbs)\n",
    "            self.out.weight.data = cmars_actor.act.action_out.linear.weight.data\n",
    "\n",
    "        def forward(self, obs):\n",
    "            obs = self.af(self.lin1(obs))\n",
    "\n",
    "            for item in self.midlayers:\n",
    "                obs = self.af(item(obs))    \n",
    "\n",
    "            logits = self.out(obs)\n",
    "\n",
    "            return logits\n",
    "\n",
    "    embb_cmars_wrapper = CMARS_Actor_Wrapper(embb_actor, \"embb\")\n",
    "\n",
    "    return embb_cmars_wrapper\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_argmax(input_size):\n",
    "    \n",
    "    # Take sum of the input vars\n",
    "    c01 = torch.zeros([1, 1, input_size+1])\n",
    "    c01[0][0][0] = 1\n",
    "\n",
    "    c02 = torch.zeros([1, 1, input_size+1])\n",
    "    c02[0][0][0] = 1\n",
    "    c02[0][0][-1] = 1\n",
    "\n",
    "    return c01, c02\n",
    "\n",
    "def cmars() -> nn.Sequential:\n",
    "    base_model = get_model()\n",
    "\n",
    "    class MyModel(nn.ModuleList):\n",
    "        def __init__(self, device=torch.device(\"cpu\")):\n",
    "            super(MyModel, self).__init__()\n",
    "\n",
    "            input_size = 19\n",
    "            self.input_size = input_size\n",
    "            c01, c02 = get_params_argmax(input_size)\n",
    "            \n",
    "            self.ft = torch.nn.Flatten()\n",
    "\n",
    "            #################\n",
    "            # Model\n",
    "            ################# \n",
    "            self.base_model = base_model\n",
    "            \n",
    "            #################\n",
    "            # Input summation\n",
    "            #################\n",
    "            self.input_conv1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=input_size+1)\n",
    "            self.input_conv1.weight = torch.nn.Parameter(c01, requires_grad=True)\n",
    "            self.input_conv1.bias = torch.nn.Parameter(torch.zeros_like(self.input_conv1.bias, requires_grad=True))\n",
    "            \n",
    "            self.input_conv2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=input_size+1)\n",
    "            self.input_conv2.weight = torch.nn.Parameter(c02, requires_grad=True)\n",
    "            self.input_conv2.bias = torch.nn.Parameter(torch.zeros_like(self.input_conv2.bias, requires_grad=True))            \n",
    "\n",
    "        def forward(self, obs):\n",
    "            # input processing\n",
    "            input1 = self.input_conv1(obs)\n",
    "            input2 = self.input_conv2(obs)\n",
    "            \n",
    "            # the model\n",
    "            copy1_logits = self.base_model(input1)\n",
    "            copy2_logits = self.base_model(input2)\n",
    "            \n",
    "            return self.ft(torch.concat((copy1_logits, copy2_logits), dim=1))\n",
    "\n",
    "    model = MyModel()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._use_feature_normalization:  False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CMARS_Actor_Wrapper(\n",
       "  (0): ReLU()\n",
       "  (1): Linear(in_features=19, out_features=32, bias=True)\n",
       "  (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "  (3): Linear(in_features=32, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = get_model()\n",
    "base_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx, onnxscript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self._use_feature_normalization:  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mzi/anaconda3/envs/crown/lib/python3.11/site-packages/torch/onnx/_internal/exporter.py:137: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "torch_input = torch.randn(1, 1, 38)\n",
    "model = cmars()\n",
    "onnx_program = torch.onnx.dynamo_export(model, torch_input)\n",
    "onnx_program.save(\"camrs.onnx\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy comparative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_plain_model(scen=\"normal_1\", hidden_size=32, layer_count=2):\n",
    "\n",
    "    class MyModel(nn.ModuleList):\n",
    "        def __init__(self, device=torch.device(\"cpu\")):\n",
    "            super(MyModel, self).__init__()\n",
    "\n",
    "            input_size, output_size = 4, 4\n",
    "            self.input_size = input_size\n",
    "            c01, c02 = get_params_argmax(input_size)\n",
    "            \n",
    "            self.af = nn.ReLU()\n",
    "            self.ft = torch.nn.Flatten()\n",
    "\n",
    "            #################\n",
    "            # Model\n",
    "            ################# \n",
    "            # self.lin1 = nn.Linear(input_size, output_size)\n",
    "            \n",
    "            #################\n",
    "            # Input summation\n",
    "            #################\n",
    "            self.input_conv1 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=input_size+1)\n",
    "            self.input_conv1.weight = torch.nn.Parameter(c01, requires_grad=True)\n",
    "            self.input_conv1.bias = torch.nn.Parameter(torch.zeros_like(self.input_conv1.bias, requires_grad=True))\n",
    "            \n",
    "            self.input_conv2 = nn.Conv1d(in_channels=1, out_channels=1, kernel_size=input_size+1)\n",
    "            self.input_conv2.weight = torch.nn.Parameter(c02, requires_grad=True)\n",
    "            self.input_conv2.bias = torch.nn.Parameter(torch.zeros_like(self.input_conv2.bias, requires_grad=True))            \n",
    "\n",
    "        def forward(self, obs):\n",
    "            # input processing\n",
    "            input1 = self.input_conv1(obs)\n",
    "            input2 = self.input_conv2(obs)\n",
    "            \n",
    "            # the model\n",
    "            # lin1 = self.lin1(input1)\n",
    "            # lin2 = self.lin1(input2)\n",
    "            \n",
    "            return self.ft(torch.concat((input1, input2), dim=1))\n",
    "\n",
    "    model = MyModel()\n",
    "\n",
    "    return model\n",
    "\n",
    "def plain_comparative() -> nn.Sequential:\n",
    "    model = make_plain_model()\n",
    "    return model\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.17 ('crown')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a23f3777b0830da074693c2e4ace01b402de73cf315f82a738a3e7426d816e98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
